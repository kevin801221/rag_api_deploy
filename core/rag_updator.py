import os
import json
import time
import argparse
import sys
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional
from dotenv import load_dotenv

# å°å…¥å‡½æ•¸å¼ RAPTOR æ ¸å¿ƒ
from .raptor_core import (
    # åˆå§‹åŒ–å’Œé…ç½®
    init_raptor_core, get_config, update_config,
    # API Key å’Œæ¨¡å‹è¨­ç½®
    load_api_keys_from_files, setup_models, setup_qdrant,
    # æ–‡æª”è™•ç†
    process_single_file_with_raptor, calculate_file_hash,
    # å‘é‡å­˜å„²
    add_texts_to_vectorstore, build_rag_chain,
    # çµ±è¨ˆå’Œå…ƒæ•¸æ“š
    get_vectorstore_stats, get_qdrant_file_metadata,
    # é«˜ç´šä¾¿æ·å‡½æ•¸
    full_setup_raptor_system, get_current_state, reset_raptor_core
)

# è¼‰å…¥ç’°å¢ƒè®Šé‡
load_dotenv()


# ===============================================
# é…ç½®æ–‡ä»¶ç®¡ç†å‡½æ•¸
# ===============================================

def load_updator_config(config_file: str = "rag_config.json") -> Dict:
    """è¼‰å…¥æˆ–å‰µå»ºæ›´æ–°å™¨é…ç½®æ–‡ä»¶
    
    Args:
        config_file: é…ç½®æ–‡ä»¶è·¯å¾‘
        
    Returns:
        Dict: é…ç½®å­—å…¸
    """
    default_config = {
        "document_directory": "knowledge_docs",
        "last_update": None,
        "file_hashes": {},
        "chunk_size": 1500,
        "chunk_overlap": 150,
        "n_levels": 3,
        "embedding_model": "text-embedding-3-small",
        "llm_model": "gpt-4o-mini",
        "retrieval_k": 6,
        "batch_size": 20,
        "max_tokens_per_batch": 100000
    }
    
    if os.path.exists(config_file):
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
            # åˆä½µæ–°è¨­å®š
            for key, value in default_config.items():
                if key not in config:
                    config[key] = value
            print(f"âœ… è¼‰å…¥é…ç½®æ–‡ä»¶: {config_file}")
        except Exception as e:
            print(f"âš ï¸ è®€å–é…ç½®æ–‡ä»¶å¤±æ•—ï¼Œä½¿ç”¨é»˜èªé…ç½®: {e}")
            config = default_config
    else:
        config = default_config
        print("ğŸ“‹ ä½¿ç”¨é»˜èªé…ç½®")
    
    return config


def save_updator_config(config: Dict, config_file: str = "rag_config.json"):
    """ä¿å­˜æ›´æ–°å™¨é…ç½®æ–‡ä»¶
    
    Args:
        config: é…ç½®å­—å…¸
        config_file: é…ç½®æ–‡ä»¶è·¯å¾‘
    """
    try:
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        print(f"âœ… é…ç½®å·²ä¿å­˜åˆ°: {config_file}")
    except Exception as e:
        print(f"âš ï¸ ä¿å­˜é…ç½®æ–‡ä»¶å¤±æ•—: {e}")


def check_config_changed(config: Dict, custom_config: Dict) -> bool:
    """æª¢æŸ¥é—œéµé…ç½®æ˜¯å¦æœ‰è®Šæ›´
    
    Args:
        config: ç•¶å‰é…ç½®
        custom_config: è‡ªå®šç¾©é…ç½®
        
    Returns:
        bool: æ˜¯å¦æœ‰é…ç½®è®Šæ›´
    """
    if not custom_config:
        return False
        
    key_params = ['chunk_size', 'chunk_overlap', 'n_levels']
    changed = False
    
    for param in key_params:
        if param in custom_config:
            old_value = config.get(param)
            new_value = custom_config[param]
            if old_value != new_value:
                print(f"ğŸ”„ é…ç½®è®Šæ›´: {param} = {old_value} â†’ {new_value}")
                changed = True
                
    return changed


# ===============================================
# ç³»çµ±åˆå§‹åŒ–å‡½æ•¸
# ===============================================

def initialize_raptor_system(config: Dict) -> bool:
    """åˆå§‹åŒ– RAPTOR ç³»çµ±
    
    Args:
        config: é…ç½®å­—å…¸
        
    Returns:
        bool: åˆå§‹åŒ–æ˜¯å¦æˆåŠŸ
    """
    try:
        # è¼‰å…¥ API Keys
        api_keys = load_api_keys_from_files()
        if not api_keys:
            print("âŒ æ‰¾ä¸åˆ°ä»»ä½• OpenAI API Keyï¼")
            return False
        
        # åˆå§‹åŒ– RAPTOR æ ¸å¿ƒ
        init_raptor_core(config)
        
        # è¨­ç½®æ¨¡å‹
        if not setup_models(openai_api_keys=api_keys):
            return False
        
        # è¨­ç½® Qdrant
        qdrant_url = os.getenv("QDRANT_URL")
        qdrant_api_key = os.getenv("QDRANT_API_KEY")
        collection_name = os.getenv("QDRANT_COLLECTION", "rag_knowledge")
        
        if not qdrant_url:
            print("âŒ ç¼ºå°‘ Qdrant URL é…ç½®")
            return False
        
        # å¦‚æœä¸æ˜¯æœ¬åœ°ç«¯ï¼Œå‰‡æª¢æŸ¥ API Key
        if "localhost" not in qdrant_url and "127.0.0.1" not in qdrant_url:
            if not qdrant_api_key:
                print("âŒ é ç¨‹ Qdrant éœ€è¦ API Key")
                return False
        
        return setup_qdrant(qdrant_url, qdrant_api_key, collection_name)
        
    except Exception as e:
        print(f"âŒ RAPTOR ç³»çµ±åˆå§‹åŒ–å¤±æ•—: {e}")
        return False


# ===============================================
# æ–‡ä»¶è®Šæ›´æª¢æ¸¬å‡½æ•¸
# ===============================================

def scan_directory_files(directory: str) -> List[str]:
    """æƒæç›®éŒ„ä¸­çš„æ”¯æ´æ–‡ä»¶
    
    Args:
        directory: ç›®éŒ„è·¯å¾‘
        
    Returns:
        List[str]: æ–‡ä»¶è·¯å¾‘åˆ—è¡¨
    """
    directory_path = Path(directory)
    
    if not directory_path.exists():
        directory_path.mkdir(parents=True, exist_ok=True)
        return []
    
    current_files = []
    for ext in ['*.pdf', '*.txt', '*.docx']:
        current_files.extend(directory_path.rglob(ext))
    
    return [str(f) for f in current_files]


def check_files_changed(config: Dict,
                       target_files: Optional[List[str]] = None,
                       config_changed: bool = False) -> Tuple[bool, List[str], List[str]]:
    """æª¢æŸ¥æ–‡ä»¶æ˜¯å¦æœ‰è®Šæ›´
    
    Args:
        config: é…ç½®å­—å…¸
        target_files: æŒ‡å®šè¦æª¢æŸ¥çš„æ–‡ä»¶åˆ—è¡¨
        config_changed: é…ç½®æ˜¯å¦æœ‰è®Šæ›´
        
    Returns:
        Tuple[bool, List[str], List[str]]: (æ˜¯å¦æœ‰è®Šæ›´, æ–°æ–‡ä»¶åˆ—è¡¨, ä¿®æ”¹æ–‡ä»¶åˆ—è¡¨)
    """
    directory = config['document_directory']
    
    # ç²å–æ–‡ä»¶åˆ—è¡¨
    if target_files:
        directory_path = Path(directory)
        current_files = []
        for filename in target_files:
            file_path = directory_path / filename
            if file_path.exists():
                current_files.append(str(file_path))
            else:
                print(f"âš ï¸ æ‰¾ä¸åˆ°æŒ‡å®šæ–‡ä»¶: {filename}")
        
        if not current_files:
            print("âŒ æ²’æœ‰æ‰¾åˆ°ä»»ä½•æŒ‡å®šçš„æ–‡ä»¶")
            return False, [], []
    else:
        current_files = scan_directory_files(directory)
    
    if not current_files:
        print(f"ğŸ“‚ ç›®éŒ„ {directory} ä¸­æ²’æœ‰æ‰¾åˆ°æ”¯æ´çš„æ–‡ä»¶")
        return False, [], []
    
    # ç²å– Qdrant ä¸­å·²å­˜å„²çš„æ–‡ä»¶
    collection_name = os.getenv("QDRANT_COLLECTION", "rag_knowledge")
    qdrant_files = get_qdrant_file_metadata(collection_name)
    
    new_files = []
    changed_files = []
    current_hashes = {}
    
    for file_path in current_files:
        current_hash = calculate_file_hash(file_path)
        current_hashes[file_path] = current_hash
        
        # æª¢æŸ¥æœ¬åœ°é…ç½®è¨˜éŒ„
        in_local_config = file_path in config['file_hashes']
        local_hash_match = in_local_config and config['file_hashes'][file_path] == current_hash
        
        # æª¢æŸ¥ Qdrant ä¸­çš„è¨˜éŒ„
        in_qdrant = file_path in qdrant_files
        qdrant_hash_match = in_qdrant and qdrant_files[file_path] == current_hash
        
        # è©³ç´°ç‹€æ…‹æª¢æŸ¥
        print(f"ğŸ” æª¢æŸ¥æ–‡ä»¶: {file_path}")
        print(f"   æœ¬åœ°é…ç½®: {'âœ…' if in_local_config else 'âŒ'} | å“ˆå¸ŒåŒ¹é…: {'âœ…' if local_hash_match else 'âŒ'}")
        print(f"   Qdrant:   {'âœ…' if in_qdrant else 'âŒ'} | å“ˆå¸ŒåŒ¹é…: {'âœ…' if qdrant_hash_match else 'âŒ'}")
        
        # å¦‚æœé…ç½®æœ‰è®Šæ›´ï¼Œå¼·åˆ¶é‡æ–°è™•ç†
        if config_changed:
            print(f"   ğŸ”„ é…ç½®è®Šæ›´ï¼Œå¼·åˆ¶é‡æ–°è™•ç†")
            changed_files.append(file_path)
        # æª¢æŸ¥é‚è¼¯ï¼šå…©é‚Šéƒ½è¦æœ‰è¨˜éŒ„ä¸”å“ˆå¸ŒåŒ¹é…æ‰è·³é
        elif in_local_config and local_hash_match and in_qdrant and qdrant_hash_match:
            print(f"   â¡ï¸ è·³é: å·²å­˜åœ¨ä¸”æœªä¿®æ”¹")
        else:
            # éœ€è¦è™•ç†çš„æƒ…æ³
            if not in_local_config and not in_qdrant:
                new_files.append(file_path)
                print(f"   â¡ï¸ æ¨™è¨˜ç‚º: æ–°æ–‡ä»¶")
            elif not in_qdrant or not qdrant_hash_match:
                changed_files.append(file_path)
                print(f"   â¡ï¸ æ¨™è¨˜ç‚º: éœ€è¦æ›´æ–°ï¼ˆQdrant ä¸­ç¼ºå¤±æˆ–ä¸åŒ¹é…ï¼‰")
            elif not in_local_config or not local_hash_match:
                changed_files.append(file_path)
                print(f"   â¡ï¸ æ¨™è¨˜ç‚º: éœ€è¦æ›´æ–°ï¼ˆæœ¬åœ°é…ç½®ç¼ºå¤±æˆ–ä¸åŒ¹é…ï¼‰")
    
    # æ›´æ–°æœ¬åœ°é…ç½®ä¸­çš„å“ˆå¸Œå€¼
    for file_path, hash_value in current_hashes.items():
        config['file_hashes'][file_path] = hash_value
    
    has_changes = bool(new_files or changed_files)
    
    if has_changes:
        print(f"\nğŸ“ ç™¼ç¾è®Šæ›´: æ–°å¢ {len(new_files)} å€‹ï¼Œä¿®æ”¹ {len(changed_files)} å€‹æ–‡ä»¶")
    else:
        print(f"\nâœ… æ‰€æœ‰ {len(current_files)} å€‹æ–‡ä»¶éƒ½å·²è™•ç†ä¸”æœªä¿®æ”¹")
    
    return has_changes, new_files, changed_files


# ===============================================
# æ–‡ä»¶è™•ç†å‡½æ•¸
# ===============================================

def process_single_file(file_path: str, config: Dict) -> bool:
    """è™•ç†å–®å€‹æ–‡ä»¶
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾‘
        config: é…ç½®å­—å…¸
        
    Returns:
        bool: è™•ç†æ˜¯å¦æˆåŠŸ
    """
    try:
        print(f"ğŸ“„ è™•ç†æ–‡ä»¶: {file_path}")
        
        # ä½¿ç”¨ RAPTOR è™•ç†æ–‡ä»¶
        all_texts, file_hash = process_single_file_with_raptor(file_path)
        
        if all_texts:
            # å‰µå»ºå…ƒæ•¸æ“š
            metadata_list = [{
                'source': file_path,
                'file_hash': file_hash,
                'timestamp': datetime.now().isoformat()
            } for _ in all_texts]
            
            # æ·»åŠ åˆ°å‘é‡å­˜å„²
            success = add_texts_to_vectorstore(all_texts, metadata_list)
            if success:
                # æ›´æ–°é…ç½®ä¸­çš„æ–‡ä»¶å“ˆå¸Œ
                config['file_hashes'][file_path] = file_hash
                print(f"âœ… å®Œæˆ: {file_path}")
                return True
            else:
                print(f"âŒ å‘é‡å­˜å„²å¤±æ•—: {file_path}")
                return False
        else:
            print(f"âš ï¸ ç©ºæ–‡ä»¶: {file_path}")
            return True  # ç©ºæ–‡ä»¶ä¸ç®—éŒ¯èª¤
        
    except Exception as e:
        print(f"âŒ è™•ç†å¤±æ•— {file_path}: {e}")
        return False


def process_file_list(files: List[str], config: Dict) -> bool:
    """è™•ç†æ–‡ä»¶åˆ—è¡¨
    
    Args:
        files: æ–‡ä»¶è·¯å¾‘åˆ—è¡¨
        config: é…ç½®å­—å…¸
        
    Returns:
        bool: è™•ç†æ˜¯å¦æˆåŠŸ
    """
    if not files:
        return True
    
    print(f"ğŸ“„ è™•ç† {len(files)} å€‹æ–‡ä»¶...")
    
    success_count = 0
    for i, file_path in enumerate(files, 1):
        print(f"[{i}/{len(files)}] è™•ç†: {Path(file_path).name}")
        if process_single_file(file_path, config):
            success_count += 1
    
    print(f"ğŸ“Š è™•ç†çµæœ: {success_count}/{len(files)} å€‹æ–‡ä»¶æˆåŠŸ")
    return success_count == len(files)


# ===============================================
# èª¿è©¦å‡½æ•¸
# ===============================================

def debug_qdrant_structure():
    """èª¿è©¦ Qdrant ä¸­çš„æ•¸æ“šçµæ§‹"""
    from .raptor_core import _global_state
    
    qdrant_client = _global_state.get('qdrant_client')
    if not qdrant_client:
        print("âŒ Qdrant å®¢æˆ¶ç«¯æœªåˆå§‹åŒ–")
        return
    
    try:
        collection_name = os.getenv("QDRANT_COLLECTION", "rag_knowledge")
        points, _ = qdrant_client.scroll(
            collection_name=collection_name,
            limit=3,  # åªçœ‹å‰ 3 å€‹é»
            with_payload=True,
            with_vectors=False
        )
        
        print(f"\nğŸ” Qdrant æ•¸æ“šçµæ§‹èª¿è©¦ (é›†åˆ: {collection_name})")
        print("=" * 50)
        
        for i, point in enumerate(points, 1):
            print(f"\né» {i} (ID: {point.id}):")
            if point.payload:
                import json
                print("Payload çµæ§‹:")
                print(json.dumps(point.payload, indent=2, ensure_ascii=False, default=str))
            else:
                print("  ç„¡ payload")
        
    except Exception as e:
        print(f"âŒ èª¿è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()


# ===============================================
# ä¸»è¦æ›´æ–°å‡½æ•¸
# ===============================================

def update_knowledge_base(custom_config: Dict = None, 
                         target_files: List[str] = None,
                         config_file: str = "rag_config.json") -> str:
    """æª¢æŸ¥ä¸¦æ›´æ–°çŸ¥è­˜åº« - ä¸»è¦å‡½æ•¸
    
    Args:
        custom_config: è‡ªå®šç¾©é…ç½®
        target_files: æŒ‡å®šè¦è™•ç†çš„æ–‡ä»¶åˆ—è¡¨
        config_file: é…ç½®æ–‡ä»¶è·¯å¾‘
        
    Returns:
        str: æ›´æ–°çµæœæè¿°
    """
    print("ğŸ”„ æª¢æŸ¥çŸ¥è­˜åº«")
    print("=" * 30)
    
    try:
        # è¼‰å…¥é…ç½®
        config = load_updator_config(config_file)
        
        # æª¢æŸ¥ç³»çµ±æ˜¯å¦å·²åˆå§‹åŒ–
        current_state = get_current_state()
        if not current_state.get('qdrant_connected'):
            print("ğŸš¨ ç³»çµ±æœªåœ¨ä¸»æ‡‰ç”¨ç¨‹å¼ä¸­æ­£ç¢ºåˆå§‹åŒ–ï¼Œå˜—è©¦é‡æ–°åˆå§‹åŒ–...")
            if not initialize_raptor_system(config):
                return "âŒ ç³»çµ±åˆå§‹åŒ–å¤±æ•—"
        else:
            print("âœ… ä½¿ç”¨ä¸»æ‡‰ç”¨ç¨‹å¼å·²åˆå§‹åŒ–çš„ç³»çµ±ç‹€æ…‹")
        
        # æª¢æŸ¥æ–‡ä»¶è®Šæ›´
        has_changes, new_files, changed_files = check_files_changed(
            config, target_files, config_changed
        )
        
        if not has_changes:
            # ç¢ºä¿ RAG éˆå­˜åœ¨
            build_rag_chain()
            save_updator_config(config, config_file)
            return "âœ… é€™äº›è³‡æ–™éƒ½åšé RAG äº†ï¼"
        
        # è™•ç†è®Šæ›´æ–‡ä»¶
        files_to_process = new_files + changed_files
        success = process_file_list(files_to_process, config)
        
        if success:
            # å»ºç«‹ RAG éˆ
            build_rag_chain()
            
            # æ›´æ–°é…ç½®
            config['last_update'] = datetime.now().isoformat()
            save_updator_config(config, config_file)
            
            return f"âœ… å·²æ›´æ–° {len(files_to_process)} å€‹æ–‡ä»¶çš„ RAG ç´¢å¼•"
        else:
            return "âŒ æ›´æ–° RAG ç´¢å¼•å¤±æ•—"
            
    except Exception as e:
        return f"âŒ æ›´æ–°å¤±æ•—: {e}"


# ===============================================
# ä¾¿æ·å‡½æ•¸
# ===============================================

def quick_update() -> str:
    """å¿«é€Ÿæ›´æ–° - ä½¿ç”¨é è¨­è¨­å®š
    
    Returns:
        str: æ›´æ–°çµæœ
    """
    return update_knowledge_base()


def update_specific_files(filenames: List[str]) -> str:
    """æ›´æ–°æŒ‡å®šæ–‡ä»¶
    
    Args:
        filenames: æ–‡ä»¶ååˆ—è¡¨
        
    Returns:
        str: æ›´æ–°çµæœ
    """
    return update_knowledge_base(target_files=filenames)


def update_with_config(chunk_size: int = None,
                      chunk_overlap: int = None, 
                      n_levels: int = None,
                      **kwargs) -> str:
    """ä½¿ç”¨è‡ªå®šç¾©é…ç½®æ›´æ–°
    
    Args:
        chunk_size: æ–‡æœ¬å¡Šå¤§å°
        chunk_overlap: é‡ç–Šå¤§å°
        n_levels: RAPTOR å±¤æ•¸
        **kwargs: å…¶ä»–é…ç½®åƒæ•¸
        
    Returns:
        str: æ›´æ–°çµæœ
    """
    custom_config = {}
    
    if chunk_size is not None:
        custom_config['chunk_size'] = chunk_size
    if chunk_overlap is not None:
        custom_config['chunk_overlap'] = chunk_overlap
    if n_levels is not None:
        custom_config['n_levels'] = n_levels
    
    custom_config.update(kwargs)
    
    return update_knowledge_base(custom_config)


# ===============================================
# çµ±è¨ˆå’Œç‹€æ…‹å‡½æ•¸
# ===============================================

def show_system_status():
    """é¡¯ç¤ºç³»çµ±ç‹€æ…‹"""
    print("\nğŸ“Š ç³»çµ±ç‹€æ…‹:")
    print("=" * 30)
    
    # é¡¯ç¤º RAPTOR æ ¸å¿ƒç‹€æ…‹
    state = get_current_state()
    for key, value in state.items():
        status = "âœ…" if value else "âŒ"
        print(f"{status} {key}: {value}")
    
    # é¡¯ç¤ºå‘é‡åº«çµ±è¨ˆ
    stats = get_vectorstore_stats()
    if stats:
        print(f"\nğŸ“ˆ å‘é‡åº«çµ±è¨ˆ:")
        for key, value in stats.items():
            print(f"   {key}: {value}")
    
    # é¡¯ç¤ºé…ç½®
    config = get_config()
    if config:
        print(f"\nâš™ï¸ ç•¶å‰é…ç½®:")
        key_configs = ['chunk_size', 'chunk_overlap', 'n_levels', 'retrieval_k']
        for key in key_configs:
            if key in config:
                print(f"   {key}: {config[key]}")


def get_file_status(directory: str = "knowledge_docs") -> Dict:
    """ç²å–æ–‡ä»¶ç‹€æ…‹
    
    Args:
        directory: æ–‡æª”ç›®éŒ„
        
    Returns:
        Dict: æ–‡ä»¶ç‹€æ…‹ä¿¡æ¯
    """
    files = scan_directory_files(directory)
    config = load_updator_config()
    
    file_status = {
        'total_files': len(files),
        'processed_files': 0,
        'unprocessed_files': 0,
        'files_info': []
    }
    
    for file_path in files:
        current_hash = calculate_file_hash(file_path)
        in_config = file_path in config['file_hashes']
        hash_match = in_config and config['file_hashes'][file_path] == current_hash
        
        status = "å·²è™•ç†" if in_config and hash_match else "æœªè™•ç†"
        if status == "å·²è™•ç†":
            file_status['processed_files'] += 1
        else:
            file_status['unprocessed_files'] += 1
        
        file_status['files_info'].append({
            'path': file_path,
            'status': status,
            'hash': current_hash[:8] + "..." if current_hash else "ç„¡æ³•è¨ˆç®—"
        })
    
    return file_status


# ===============================================
# å‘½ä»¤è¡Œåƒæ•¸è§£æ
# ===============================================

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œåƒæ•¸"""
    parser = argparse.ArgumentParser(
        description="RAG æ›´æ–°å™¨ - æ™ºèƒ½æ–‡ä»¶æª¢æ¸¬èˆ‡çŸ¥è­˜åº«æ›´æ–°ï¼ˆå‡½æ•¸å¼ç‰ˆæœ¬ï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¯„ä¾‹:
  python rag_updator.py                                     # æ›´æ–°æ‰€æœ‰æ–‡ä»¶
  python rag_updator.py --path file1.pdf file2.txt         # åªè™•ç†æŒ‡å®šæ–‡ä»¶
  python rag_updator.py --chunk_size 1000                  # è‡ªå®šç¾©æ–‡æœ¬å¡Šå¤§å°
  python rag_updator.py --path file1.pdf --chunk_size 800 --n_levels 2  # çµ„åˆä½¿ç”¨
  python rag_updator.py --debug                            # èª¿è©¦ Qdrant çµæ§‹
  python rag_updator.py --status                           # é¡¯ç¤ºç³»çµ±ç‹€æ…‹
        """
    )
    
    parser.add_argument(
        '--path', 
        nargs='+',
        help='æŒ‡å®šè¦è™•ç†çš„æ–‡ä»¶åç¨±ï¼ˆåœ¨ knowledge_docs ç›®éŒ„ä¸‹ï¼‰'
    )
    
    parser.add_argument(
        '--chunk_size', 
        type=int,
        help='æ–‡æœ¬åˆ†å¡Šå¤§å° (é è¨­: 1500)'
    )
    
    parser.add_argument(
        '--chunk_overlap', 
        type=int,
        help='æ–‡æœ¬åˆ†å¡Šé‡ç–Šå¤§å° (é è¨­: 150)'
    )
    
    parser.add_argument(
        '--n_levels', 
        type=int,
        help='RAPTOR å±¤æ•¸ (é è¨­: 3)'
    )
    
    parser.add_argument(
        '--embedding_model', 
        type=str,
        help='åµŒå…¥æ¨¡å‹ (é è¨­: text-embedding-3-small)'
    )
    
    parser.add_argument(
        '--llm_model', 
        type=str,
        help='èªè¨€æ¨¡å‹ (é è¨­: gpt-4o-mini)'
    )
    
    parser.add_argument(
        '--retrieval_k', 
        type=int,
        help='æª¢ç´¢çµæœæ•¸é‡ (é è¨­: 6)'
    )
    
    parser.add_argument(
        '--debug',
        action='store_true',
        help='èª¿è©¦æ¨¡å¼ï¼šé¡¯ç¤º Qdrant æ•¸æ“šçµæ§‹'
    )
    
    parser.add_argument(
        '--status',
        action='store_true',
        help='é¡¯ç¤ºç³»çµ±å’Œæ–‡ä»¶ç‹€æ…‹'
    )
    
    return parser.parse_args()


# ===============================================
# ä¸»ç¨‹åº
# ===============================================

if __name__ == "__main__":
    args = parse_arguments()

    if args.debug:
        print("ğŸ› é€²å…¥èª¿è©¦æ¨¡å¼...")
        config = load_updator_config()
        if initialize_raptor_system(config):
            debug_qdrant_structure()
        else:
            print("âŒ ç³»çµ±åˆå§‹åŒ–å¤±æ•—ï¼Œç„¡æ³•é€²è¡Œèª¿è©¦")

    elif args.status:
        show_system_status()

    else:
        custom_config = {}
        if args.chunk_size is not None:
            custom_config['chunk_size'] = args.chunk_size
        if args.chunk_overlap is not None:
            custom_config['chunk_overlap'] = args.chunk_overlap
        if args.n_levels is not None:
            custom_config['n_levels'] = args.n_levels
        if args.embedding_model is not None:
            custom_config['embedding_model'] = args.embedding_model
        if args.llm_model is not None:
            custom_config['llm_model'] = args.llm_model
        if args.retrieval_k is not None:
            custom_config['retrieval_k'] = args.retrieval_k
        
        result = update_knowledge_base(
            custom_config=custom_config if custom_config else None,
            target_files=args.path
        )
        print(f"\nâœ¨ æ›´æ–°å®Œæˆ: {result}")